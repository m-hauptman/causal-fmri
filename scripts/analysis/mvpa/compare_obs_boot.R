# compare_obs_boot.R
# compare observed results (ROI MVPA) to null distributions
# written by MH, adapted from GE

library(dplyr)
library(tidyr)

# set defaults
wd = ""
setwd(wd)
test = "biomech"

rois1 <- c("PC","TPJ")
rois2 <- c("Lang","Logic")
hemis <- c("lh","rh")
contrasts <- c("soc_vs_phys", "caus_vs_rest")
subs <- c("IRNX_05","IRNX_06","IRNX_07","IRNX_08","IRNX_10","IRNX_11","IRNX_12",
          "IRNX_13","IRNX_14","IRNX_15","IRNX_16","IRNX_17","IRNX_18",
          "IRNX_19","IRNX_20","IRNX_22","IRNX_23","IRNX_24","IRNX_25","IRNX_26")
n <- (length(subs)*length(contrasts)*length(rois1)*length(hemis)) + (length(subs)*length(rois2))
v_num <- 300

# anova contrast options
options(contrasts=c('contr.sum','contr.poly'))

# load true results
results = read.csv(paste0(test,'/',test,'_results_zbetamaps_all'), stringsAsFactors=T,header=T)
factors = read.csv(paste0(test,'/',test,'_factors_zbetamaps_all'), header=T, stringsAsFactors=T)

# load the bootstrapped null stats. there is one column per test.
# generated by: bootstrap_stats.R
boot.stats = read.csv(paste0(test,"_bootstrap_stats.csv"), header=T)

# set the output file.
sink(paste0(test,"_classification_stats.txt"))

# one-sample t-tests
cat("\nOne-sample within-roi t-tests", "=============================\n", sep='\n')
t.tests <- c("t.LPC_socphys", "t.RPC_socphys", "t.LTPJ_socphys", "t.RTPJ_socphys", 
             "t.LPC_causrest", "t.RPC_causrest", "t.LTPJ_causrest", "t.RTPJ_causrest", 
             "t.Lang", "t.Logic")
counter <- 1
tvals <- NULL
pvals_perm <- NULL
pvals_t <- NULL
means <- NULL
rs <- NULL
cs <- NULL
hs <- NULL

for (i in 1:length(rois1)){
  
  roi = rois1[i]

  cat("\nroi: ", roi,'\n--------------------------\n', sep='')  
  
  for (c in 1:length(contrasts)) {
    
    con = contrasts[c]
    cat("\ncontrast: ", con,'\n--------------------------\n', sep='')
    
    for (hemi in hemis) {
      # find just the accuracy values for this analysis
      vals <- results$acc[factors$roi == roi & factors$hemi == hemi & factors$v_num == v_num & factors$contrast == con]
      
      # run the one-sample t-test (one-sided, with H0: mean = 0.5).
      t.results <- t.test(vals, mu=.5, alternative='greater')
      print(t.results)
      
      # Get the column of bootstrapped null values.
      test.name <- t.tests[counter]
      boot.vals <- boot.stats[, test.name]
      
      # get non-parametric p-value using a one-sided approach.
      t.val <- t.results$statistic
      p.val.perm <- sum(boot.vals >= t.val) / length(boot.vals)
      
      # get results, store
      p.val.t <- t.results$p.value
      avg <- round((t.results$estimate * 100),1)
      
      tvals <- rbind(tvals,t.val)
      pvals_t <- rbind(pvals_t,p.val.t)
      means <- rbind(means,avg)
      pvals_perm <- rbind(pvals_perm,p.val.perm)
      rs <- rbind(rs,roi)
      cs <- rbind(cs,con)
      hs <- rbind(hs,hemi)
      
      cat("\nPermutation p-value: ", sprintf('%.5f', p.val.perm), '\n', sep='')
      counter<-counter+1  
    }
  }
}

for (i in 1:length(rois2)){
  
  roi = rois2[i]
  
  if (roi == "Lang") {
    con = "lang_vs_math"
  }
  else {
    con = "log_vs_lang"
  }
  
  cat("\nroi: ", roi,'\n--------------------------\n', sep='')
  cat("\ncontrast: ", con,'\n--------------------------\n', sep='')
    
  # find just the accuracy values for this analysis
  vals <- results$acc[factors$roi == roi & factors$v_num == v_num & factors$contrast == con]
  
  # run the one-sample t-test (one-sided, with H0: mean = 0.5).
  t.results <- t.test(vals, mu=.5, alternative='greater')
  print(t.results)
  
  # Get the column of bootstrapped null values.
  test.name <- t.tests[counter]
  boot.vals <- boot.stats[, test.name]
  
  # get non-parametric p-value using a one-sided approach.
  t.val <- t.results$statistic
  p.val.perm <- sum(boot.vals >= t.val) / length(boot.vals)
  
  # get results, store
  p.val.t <- t.results$p.value
  avg <- round((t.results$estimate * 100),1)
  
  tvals <- rbind(tvals,t.val)
  pvals_t <- rbind(pvals_t,p.val.t)
  means <- rbind(means,avg)
  pvals_perm <- rbind(pvals_perm,p.val.perm)
  rs <- rbind(rs,roi)
  cs <- rbind(cs,con)
  hs <- rbind(hs,"lh")
  
  cat("\nPermutation p-value: ", sprintf('%.5f', p.val.perm), '\n', sep='')
  counter<-counter+1
  
}

# make dataframe one sample results (need for table)
df <- data.frame(
  rs = rs,
  cs = cs,
  hs = hs,
  means = means,
  tvals = round(tvals,2),
  pvals_perm = round(pvals_perm,4),
  pvals_t = round(pvals_t,4)
)

df$bonferroni <-
  p.adjust(df$pvals_t,
           method = "bonferroni"
  )

# get into right format for table
df <- df %>% 
  mutate(mean.of.x = paste0(as.character(means),"%",sep="")) %>%
  group_by(cs) %>% 
  arrange(desc(rs), .by_group = TRUE) %>% 
  arrange(desc(cs))

# write file
#options(scipen=999)
write.csv(df, paste0(test,"_onesample_stats.csv"), quote=F, row.names=F)

# Close connection to results file.
sink()
